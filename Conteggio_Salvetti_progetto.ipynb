{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conteggio_Salvetti_progetto.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLSW1i4vesXe"
      },
      "source": [
        "#dichiarazione di tutte le librerie necessarie per l'esecuzione del codice\n",
        "!pip install feel_it\n",
        "import pandas as pd\n",
        "import networkx.algorithms as nxa\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "import itertools\n",
        "import nltk\n",
        "import wordcloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from matplotlib.pyplot import figure\n",
        "from wordcloud import WordCloud\n",
        "from feel_it import EmotionClassifier, SentimentClassifier\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"italian\")) \n",
        "new_stopwords = [\"pi\", \"più\",\"sar\",\"de\",\"et\",\"lor\"]\n",
        "second_stopwrds = set(stopwords.words(\"english\")) \n",
        "stop_words = stop_words.union(new_stopwords)\n",
        "stop_words = stop_words.union(second_stopwrds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGdnMrRWffbV"
      },
      "source": [
        "from google.colab import files #Istruzione che permette di caricare i file da analizzare\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qurv4bFtIS5c"
      },
      "source": [
        "tree=ET.parse('Corpus_Tesi.xml')#Blocco che permette di leggere e creare una genialogia sul file XML\n",
        "root= tree.getroot()\n",
        "location=root.findall('newsFrom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w92kcuRyDqU3"
      },
      "source": [
        "def person_doc(var): #Funzione che viene richiamata nel primo blocco principale, questa ci consente di trovare per ogni newsFrom i personaggi contenuti\n",
        "  doc_news=var\n",
        "  frms=doc_news.findall('.//newsFrom')#element.findall cerca tutti gli elementi con un tag che è direttamente figlio dell'elemento corrente\n",
        "  people_in_doc=[]\n",
        "  for frm in frms:\n",
        "     people_in_frm=[]\n",
        "     x=frm.findall('.//person')\n",
        "     for p_dc in x:\n",
        "      people_in_frm.append(p_dc.text)\n",
        "     people_in_doc.append(people_in_frm)\n",
        "  return(people_in_doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMUt4NlFGC_d"
      },
      "source": [
        "def funz_edg(var2):#Funzione che richiamata ci permette di creare gli \"angoli\" del social network\n",
        "  f_network=var2\n",
        "  f_network=itertools.combinations(f_network,2)\n",
        "  for i in f_network:\n",
        "    edg.append(i)\n",
        "  return(edg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUPO5zeSIj-6"
      },
      "source": [
        "#Blocco principale in cui viene costruito il social network\n",
        "personaggi_net=person_doc(root)\n",
        "prsng_tot=[]\n",
        "for i in personaggi_net:\n",
        "  prsng_tot.append(list(sorted(set(i)))) \n",
        "lista_pers = sorted(set(sum(prsng_tot,[])))\n",
        "n_pers=len(lista_pers)#Calcolo delle persone nel documento\n",
        "edg=[]\n",
        "for i in prsng_tot:\n",
        "  funz_edg(i)\n",
        "\n",
        "network_documento=nx.Graph()#Blocco che crea il social network\n",
        "network_documento.add_nodes_from(lista_pers)\n",
        "network_documento.add_edges_from(edg)\n",
        "\n",
        "comp=nx.connected_components(network_documento)#Istruzioni per il calcolo dei cliques e dei components\n",
        "cliq=nx.find_cliques(network_documento)\n",
        "\n",
        "print('Personaggi presenti nel documento',n_pers)#Serie di stampa a schermo di valori connessi al network\n",
        "print('Clique del network:', len(list(cliq)))\n",
        "print('Densità del network:', nx.density(network_documento))\n",
        "print('Coefficiente medio di clustering:', nx.average_clustering(network_documento))\n",
        "print('Componenti connessi:', len(list(comp)))\n",
        "\n",
        "#Istruzioni della libreria per visualizzare il social network\n",
        "plt.figure(figsize=(30,25)) \n",
        "plt.title(\"Social network according with documentation\",fontsize = 35)\n",
        "n_pers=nx.spring_layout(network_documento,k=2,scale=1, iterations=70)\n",
        "nx.draw(network_documento,n_pers,node_color='r')\n",
        "nx.draw_networkx_labels(network_documento,n_pers)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsUUcyz48kuC"
      },
      "source": [
        "print('Network Pagerank del documento selezionato')#Serie di stampe di alcuni valori analizzati relativi al social network\n",
        "peso=nxa.pagerank(network_documento)#Le istruzioni presenti provengono dalla libreria networkx.algorithms\n",
        "sorted((v, f\"{c:0.2f}\") for v, c in peso.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lorsf2548JLK"
      },
      "source": [
        "print('Network closeness del documento selezionato')\n",
        "closeness=nxa.closeness_centrality(network_documento)\n",
        "sorted((v, f\"{c:0.2f}\") for v, c in closeness.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWeHDlC89L9H"
      },
      "source": [
        "print('Diametro Network del documento selezionato')\n",
        "print(nx.diameter(network_documento))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z5NrEEOJs9w"
      },
      "source": [
        "print('Network degree del documento selezionato')\n",
        "degree=nxa.degree_centrality(network_documento)\n",
        "sorted((v, f\"{c:0.2f}\") for v, c in degree.items()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMT1OKpOxHy5"
      },
      "source": [
        "#Blocco per estrarre e inserire in liste i luoghi presenti nel documento, i Topics e le persone.\n",
        "luoghi=[]\n",
        "ecnript=[]\n",
        "words=[]\n",
        "totalizzatore=0\n",
        "news_totalizzatore=0\n",
        "personaggi1=[]\n",
        "argomenti=[]\n",
        "\n",
        "for item in root.iter('newsFrom'):#Istruzione che scorre il documento alla ricerca dei luoghi\n",
        "  luoghi.append(item.text)#Istruzione che inserisce l'elemento trovato nella lista\n",
        "  news_totalizzatore=1+news_totalizzatore\n",
        "for item in root.iter('encrypted'):#Istruzione che scorre il documento alla ricerca dei Personaggi\n",
        "  totalizzatore=totalizzatore+1\n",
        "  ecnript.append(item.text)\n",
        "for item in root.iter('transc'):words.append(item.text)\n",
        "for item in root.iter('from'):luoghi.append(item.text)#Istruzione che inserisce l'elemento trovato nella lista\n",
        "for item in root.iter('newsTopic'):argomenti.append(item.text)#Istruzione che inserisce l'elemento trovato nella lista\n",
        "for item in root.iter('person'):personaggi1.append(item.text)#Istruzione che inserisce l'elemento trovato nella lista"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "res = list(filter(None, words))\n",
        "normal_words = \"\".join(res)\n",
        "wordcloud = WordCloud(stopwords = stop_words, width=2000, height=1000,collocations=True).generate(normal_words)\n",
        "plt.figure( figsize=(20,10))\n",
        "plt.imshow(wordcloud, interpolation='bilInear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSaPtVoDnag3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_sent=words\n",
        "res = []\n",
        "for val in words_sent:\n",
        "    if val != None :\n",
        "        res.append(val)\n",
        "emo=EmotionClassifier()\n",
        "emotion_salvini=emo.predict(res)\n",
        "sent=SentimentClassifier()\n",
        "sentiment_salvini=sent.predict(res)"
      ],
      "metadata": {
        "id": "ham3ViLxMm5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mention_sal_tab=pd.DataFrame({\"Sentiment\":sentiment_salvini})\n",
        "mention_sal_tab\n",
        "senti_sal_tab=pd.DataFrame({\"Emotion\":emotion_salvini})\n",
        "senti_sal_tab"
      ],
      "metadata": {
        "id": "tYlwmGoKOl-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "gw7wPnBFnF__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  plt.figure(figsize=(10,7))\n",
        "  mention_sal_tab[\"Sentiment\"].value_counts()\n",
        "  mention_sal_tab[\"Sentiment\"].value_counts().plot(kind=\"pie\",autopct='%1.0f%%')\n",
        "  plt.title(\"News Sentiment analysis 1648\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0R0utTc2g_aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  plt.figure(figsize=(10,7))\n",
        "  senti_sal_tab[\"Emotion\"].value_counts()\n",
        "  senti_sal_tab[\"Emotion\"].value_counts().plot(kind=\"pie\", autopct='%1.0f%%')\n",
        "  plt.title(\"News emotion analysis 1648\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "unrV6bSlf7tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Notizie con la cifra:\", totalizzatore)\n",
        "print(\"Notizie totali nel corpus:\", news_totalizzatore)"
      ],
      "metadata": {
        "id": "gXo6ydeZenhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guP5S-TNXDky"
      },
      "source": [
        "#Blocco per costruire una tabella che ci permette di vedere quante volte un singolo luogo è presente nel documento\n",
        "df_luoghi=pd.DataFrame(luoghi, columns=['Luoghi']) \n",
        "df_luoghi=df_luoghi.groupby(['Luoghi']).size().reset_index(name=\"Volte\")#questa istruzione permette di raggruppare i luoghi in relazione al numero di volte che compaiono\n",
        "df_luoghi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bolzYUlgXSgo"
      },
      "source": [
        "#Blocco per costruire una tabella che ci permette di vedere quante volte un singolo Topic è presente nel documento\n",
        "df_topic=pd.DataFrame(argomenti, columns=['Topics'])#L'istruzione proviene dalla libreria Panda\n",
        "df_topic=df_topic.groupby(['Topics']).size().reset_index(name=\"N°\")#questa istruzione permette di raggruppare i Topic in relazione al numero di volte che compaiono\n",
        "df_topic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsuykAwMzWch"
      },
      "source": [
        "#Blocco per costruire una tabella che ci permette di vedere quante volte un singolo Topic è presente nel documento\n",
        "df_persone=pd.DataFrame(personaggi1, columns=['Personaggi'])\n",
        "df_persone=df_persone.groupby(['Personaggi']).size().reset_index(name=\"Volte\")#questa istruzione permette di raggruppare i personaggi in relazione al numero di volte che compaiono\n",
        "df_persone"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}